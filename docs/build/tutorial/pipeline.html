<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Pipeline · TSML Documentation</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>TSML Documentation</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../index.html">HOME</a></li><li><span class="toctext">Tutorial</span><ul><li><a class="toctext" href="aggregators.html">Aggregators and Imputers</a></li><li class="current"><a class="toctext" href="pipeline.html">Pipeline</a><ul class="internal"><li><a class="toctext" href="#Workflow-of-Pipeline-1">Workflow of Pipeline</a></li><li><a class="toctext" href="#Extending-TSML-1">Extending TSML</a></li></ul></li><li><a class="toctext" href="statistics.html">Statistical Metrics</a></li><li><a class="toctext" href="monotonic.html">Monotonic Detection</a></li><li><a class="toctext" href="tsclassifier.html">TS Data Discovery</a></li></ul></li><li><span class="toctext">Manual</span><ul><li><a class="toctext" href="../man/dateproc.html">Date Processing</a></li><li><a class="toctext" href="../man/valueproc.html">Value Processing</a></li><li><a class="toctext" href="../man/aggregation.html">Aggregation</a></li><li><a class="toctext" href="../man/imputation.html">Imputation</a></li><li><a class="toctext" href="../man/monotonic.html">Monotonic Detection</a></li><li><a class="toctext" href="../man/tsclassification.html">TS Classification</a></li><li><a class="toctext" href="../man/cli.html">CLI Wrappers</a></li></ul></li><li><span class="toctext">Library</span><ul><li><a class="toctext" href="../lib/decisiontree.html">Decision Tree</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Tutorial</li><li><a href="pipeline.html">Pipeline</a></li></ul><a class="edit-page" href="https://github.com/IBM/TSML.jl/blob/master/docs/src/tutorial/pipeline.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Pipeline</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Pipeline-1" href="#Pipeline-1">Pipeline</a></h1><p>Instead of calling <code>fit!</code> and <code>transform!</code> for each transformer to process time series data, we can use the <code>Pipeline</code> transformer which does this automatically by iterating through the transformers and calling <code>fit!</code> and <code>transform!</code> repeatedly for each transformer in its argument.</p><p>Let&#39;s start again by having a function to generate a time series dataframe with some missing data.</p><pre><code class="language-julia">using Random, Dates, DataFrames
function generateDataWithMissing()
   Random.seed!(123)
   gdate = DateTime(2014,1,1):Dates.Minute(15):DateTime(2016,1,1)
   gval = Array{Union{Missing,Float64}}(rand(length(gdate)))
   gmissing = 50000
   gndxmissing = Random.shuffle(1:length(gdate))[1:gmissing]
   df = DataFrame(Date=gdate,Value=gval)
   df[:Value][gndxmissing] .= missing
   return df
end

X = generateDataWithMissing()
first(X,15)</code></pre><table class="data-frame"><thead><tr><th></th><th>Date</th><th>Value</th></tr><tr><th></th><th>Dates…</th><th>Float64⍰</th></tr></thead><tbody><p>15 rows × 2 columns</p><tr><th>1</th><td>2014-01-01T00:00:00</td><td>missing</td></tr><tr><th>2</th><td>2014-01-01T00:15:00</td><td>missing</td></tr><tr><th>3</th><td>2014-01-01T00:30:00</td><td>missing</td></tr><tr><th>4</th><td>2014-01-01T00:45:00</td><td>missing</td></tr><tr><th>5</th><td>2014-01-01T01:00:00</td><td>missing</td></tr><tr><th>6</th><td>2014-01-01T01:15:00</td><td>missing</td></tr><tr><th>7</th><td>2014-01-01T01:30:00</td><td>missing</td></tr><tr><th>8</th><td>2014-01-01T01:45:00</td><td>0.0521332</td></tr><tr><th>9</th><td>2014-01-01T02:00:00</td><td>0.26864</td></tr><tr><th>10</th><td>2014-01-01T02:15:00</td><td>0.108871</td></tr><tr><th>11</th><td>2014-01-01T02:30:00</td><td>0.163666</td></tr><tr><th>12</th><td>2014-01-01T02:45:00</td><td>0.473017</td></tr><tr><th>13</th><td>2014-01-01T03:00:00</td><td>0.865412</td></tr><tr><th>14</th><td>2014-01-01T03:15:00</td><td>missing</td></tr><tr><th>15</th><td>2014-01-01T03:30:00</td><td>missing</td></tr></tbody></table><h2><a class="nav-anchor" id="Workflow-of-Pipeline-1" href="#Workflow-of-Pipeline-1">Workflow of Pipeline</a></h2><p>Let&#39;s use the pipeline transformer to aggregate and impute:</p><pre><code class="language-julia">using Dates
using TSML
using TSML.TSMLTypes
using TSML.TSMLTransformers
using TSML: Pipeline
using TSML: DateValgator
using TSML: DateValNNer

dtvalgator = DateValgator(Dict(:dateinterval =&gt; Dates.Hour(1)))
dtvalnner = DateValNNer(Dict(:dateinterval =&gt; Dates.Hour(1)))

mypipeline = Pipeline(
  Dict( :transformers =&gt; [
            dtvalgator,
            dtvalnner
         ]
  )
)

fit!(mypipeline,X)
results = transform!(mypipeline,X)
first(results,10)</code></pre><table class="data-frame"><thead><tr><th></th><th>Date</th><th>Value</th></tr><tr><th></th><th>Dates…</th><th>Float64⍰</th></tr></thead><tbody><p>10 rows × 2 columns</p><tr><th>1</th><td>2014-01-01T00:00:00</td><td>0.108871</td></tr><tr><th>2</th><td>2014-01-01T01:00:00</td><td>0.108871</td></tr><tr><th>3</th><td>2014-01-01T02:00:00</td><td>0.108871</td></tr><tr><th>4</th><td>2014-01-01T03:00:00</td><td>0.473017</td></tr><tr><th>5</th><td>2014-01-01T04:00:00</td><td>0.361194</td></tr><tr><th>6</th><td>2014-01-01T05:00:00</td><td>0.582318</td></tr><tr><th>7</th><td>2014-01-01T06:00:00</td><td>0.918165</td></tr><tr><th>8</th><td>2014-01-01T07:00:00</td><td>0.614255</td></tr><tr><th>9</th><td>2014-01-01T08:00:00</td><td>0.690462</td></tr><tr><th>10</th><td>2014-01-01T09:00:00</td><td>0.92049</td></tr></tbody></table><p>Using the <code>Pipeline</code> transformer, it becomes straightforward to process the time series data. It also becomes trivial to extend TSML functionality by adding more transformers and making sure each support the <code>fit!</code> and <code>transform!</code> interfaces. Any new transformer can then be easily added to the <code>Pipeline</code> workflow  without invasively changing the existing codes.</p><h2><a class="nav-anchor" id="Extending-TSML-1" href="#Extending-TSML-1">Extending TSML</a></h2><p>To illustrate how simple it is to add a new transformer, below extends TSML by adding <code>CSVReader</code> transformer and added in the pipeline to process CSV data:</p><pre><code class="language-julia">using TSML.TSMLTypes
import TSML.TSMLTypes.fit!
import TSML.TSMLTypes.transform!

using CSV

mutable struct CSVReader &lt;: Transformer
    model
    args
    function CSVReader(args=Dict())
        default_args = Dict(
            :filename =&gt; &quot;&quot;,
            :dateformat =&gt; &quot;&quot;
        )
        new(nothing,mergedict(default_args,args))
    end
end

function fit!(csvrdr::CSVReader,x::T=[],y::Vector=[]) where {T&lt;:Union{DataFrame,Vector,Matrix}}
    fname = csvrdr.args[:filename]
    fmt = csvrdr.args[:dateformat]
    (fname != &quot;&quot; &amp;&amp; fmt != &quot;&quot;) || error(&quot;missing filename or date format&quot;)
    model = csvrdr.args
end

function transform!(csvrdr::CSVReader,x::T=[]) where {T&lt;:Union{DataFrame,Vector,Matrix}}
    fname = csvrdr.args[:filename]
    fmt = csvrdr.args[:dateformat]
    df = CSV.read(fname)
    ncol(df) == 2 || error(&quot;dataframe should have only two columns: Date,Value&quot;)
    rename!(df,names(df)[1]=&gt;:Date,names(df)[2]=&gt;:Value)
    df[:Date] = DateTime.(df[:Date],fmt)
    df
end</code></pre><pre><code class="language-none">transform! (generic function with 47 methods)</code></pre><p>Instead of passing table X that contains the time series, we will add  an instance of the<code>CSVReader</code> at the start of the array of transformers in the pipeline  to read the csv data. CSVReader <code>transform!</code> function converts the csv time series table into a dataframe, which will be consumed by the next transformer in the pipeline  for processing.</p><pre><code class="language-julia">fname = joinpath(dirname(pathof(TSML)),&quot;../data/testdata.csv&quot;)
csvreader = CSVReader(Dict(:filename=&gt;fname,:dateformat=&gt;&quot;d/m/y H:M&quot;))
fit!(csvreader)
csvdata = transform!(csvreader)
first(csvdata,10)</code></pre><table class="data-frame"><thead><tr><th></th><th>Date</th><th>Value</th></tr><tr><th></th><th>Dates…</th><th>Float64</th></tr></thead><tbody><p>10 rows × 2 columns</p><tr><th>1</th><td>2014-01-01T00:06:00</td><td>10.0</td></tr><tr><th>2</th><td>2014-01-01T00:18:00</td><td>10.0</td></tr><tr><th>3</th><td>2014-01-01T00:29:00</td><td>10.0</td></tr><tr><th>4</th><td>2014-01-01T00:40:00</td><td>9.9</td></tr><tr><th>5</th><td>2014-01-01T00:51:00</td><td>9.9</td></tr><tr><th>6</th><td>2014-01-01T01:02:00</td><td>10.0</td></tr><tr><th>7</th><td>2014-01-01T01:13:00</td><td>9.8</td></tr><tr><th>8</th><td>2014-01-01T01:24:00</td><td>10.0</td></tr><tr><th>9</th><td>2014-01-01T01:35:00</td><td>9.8</td></tr><tr><th>10</th><td>2014-01-01T01:46:00</td><td>10.0</td></tr></tbody></table><p>Let us now include the newly created <code>CSVReader</code> in the pipeline to read the csv data and process it by aggregation and imputation.</p><pre><code class="language-julia">mypipeline = Pipeline(
  Dict( :transformers =&gt; [
            csvreader,
            dtvalgator,
            dtvalnner
         ]
  )
)

fit!(mypipeline)
results = transform!(mypipeline)
first(results,10)</code></pre><table class="data-frame"><thead><tr><th></th><th>Date</th><th>Value</th></tr><tr><th></th><th>Dates…</th><th>Float64⍰</th></tr></thead><tbody><p>10 rows × 2 columns</p><tr><th>1</th><td>2014-01-01T00:00:00</td><td>10.0</td></tr><tr><th>2</th><td>2014-01-01T01:00:00</td><td>9.9</td></tr><tr><th>3</th><td>2014-01-01T02:00:00</td><td>10.0</td></tr><tr><th>4</th><td>2014-01-01T03:00:00</td><td>10.0</td></tr><tr><th>5</th><td>2014-01-01T04:00:00</td><td>10.0</td></tr><tr><th>6</th><td>2014-01-01T05:00:00</td><td>10.0</td></tr><tr><th>7</th><td>2014-01-01T06:00:00</td><td>10.0</td></tr><tr><th>8</th><td>2014-01-01T07:00:00</td><td>9.8</td></tr><tr><th>9</th><td>2014-01-01T08:00:00</td><td>9.85</td></tr><tr><th>10</th><td>2014-01-01T09:00:00</td><td>9.9</td></tr></tbody></table><p>Notice that there is no more the need to pass X in the arguments of <code>fit!</code> and <code>transform</code> because the data is now transmitted by the <code>CSVReader</code> instance to the other transformers in the pipeline.</p><footer><hr/><a class="previous" href="aggregators.html"><span class="direction">Previous</span><span class="title">Aggregators and Imputers</span></a><a class="next" href="statistics.html"><span class="direction">Next</span><span class="title">Statistical Metrics</span></a></footer></article></body></html>
