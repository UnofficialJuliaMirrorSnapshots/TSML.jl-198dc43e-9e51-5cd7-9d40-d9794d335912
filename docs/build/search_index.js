var documenterSearchIndex = {"docs":
[{"location":"index.html#","page":"HOME","title":"HOME","text":"Author = \"Paulito P. Palmes\"","category":"page"},{"location":"index.html#TSML-(Time-Series-Machine-Learning)-1","page":"HOME","title":"TSML (Time-Series Machine Learning)","text":"","category":"section"},{"location":"index.html#","page":"HOME","title":"HOME","text":"TSML (Time Series Machine Learning) is package  for Time Series data processing, classification, and prediction. It combines ML libraries from Python's  ScikitLearn, R's Caret, and Julia ML using a common API  and allows seamless ensembling and integration of  heterogenous ML libraries to create complex models  for robust time-series pre-processing and prediction/classification.","category":"page"},{"location":"index.html#Package-Features-1","page":"HOME","title":"Package Features","text":"","category":"section"},{"location":"index.html#","page":"HOME","title":"HOME","text":"TS aggregation based on time/date interval\nTS imputation based on Nearest Neighbors\nTS statistical metrics of data quality\nTS classification for automatic data discovery\nTS prediction with more than 100+ libraries from caret, scikitlearn, and julia\nTS date/val matrix conversion of 1-d TS using sliding windows for ML input\nPipeline API allows high-level description of the processing workflow\nEasily extensible architecture by using just two main interfaces: fit and transform","category":"page"},{"location":"index.html#Installation-1","page":"HOME","title":"Installation","text":"","category":"section"},{"location":"index.html#","page":"HOME","title":"HOME","text":"TSML is in the Julia Official package registry.  The latest release can be installed at the Julia  prompt using Julia's package management:","category":"page"},{"location":"index.html#","page":"HOME","title":"HOME","text":"julia> ]add TSML","category":"page"},{"location":"index.html#","page":"HOME","title":"HOME","text":"or","category":"page"},{"location":"index.html#","page":"HOME","title":"HOME","text":"julia> using Pkg\njulia> pkg\"add TSML\"","category":"page"},{"location":"index.html#","page":"HOME","title":"HOME","text":"or","category":"page"},{"location":"index.html#","page":"HOME","title":"HOME","text":"julia> using Pkg\njulia> Pkg.add(\"TSML\")","category":"page"},{"location":"index.html#","page":"HOME","title":"HOME","text":"Once TSML is installed, you can load the TSML package by:","category":"page"},{"location":"index.html#","page":"HOME","title":"HOME","text":"julia> using TSML","category":"page"},{"location":"index.html#","page":"HOME","title":"HOME","text":"or ","category":"page"},{"location":"index.html#","page":"HOME","title":"HOME","text":"julia> import TSML","category":"page"},{"location":"index.html#","page":"HOME","title":"HOME","text":"Generally, you will need the different transformers and utils in TSML for time-series processing. To use them, it is standard in TSML code to have the following declared at the topmost part of your application:","category":"page"},{"location":"index.html#","page":"HOME","title":"HOME","text":"using TSML \nusing TSML.TSMLTransformers\nusing TSML.TSMLTypes\nusing TSML.Utils","category":"page"},{"location":"tutorial/aggregators.html#","page":"Aggregators and Imputers","title":"Aggregators and Imputers","text":"Author = \"Paulito P. Palmes\"","category":"page"},{"location":"tutorial/aggregators.html#Aggregators-and-Imputers-1","page":"Aggregators and Imputers","title":"Aggregators and Imputers","text":"","category":"section"},{"location":"tutorial/aggregators.html#","page":"Aggregators and Imputers","title":"Aggregators and Imputers","text":"The package assumes a two-column input composed of Dates and Values.  The first part of the workflow aggregates values based on the specified  date/time interval which minimizes occurence of missing values and noise.  The aggregated data is then left-joined to the complete sequence of dates  in a specified date/time interval. Remaining missing values are replaced  by k nearest neighbors where k is the symmetric distance from the location  of missing value. This approach can be called several times until there  are no more missing values.","category":"page"},{"location":"tutorial/aggregators.html#","page":"Aggregators and Imputers","title":"Aggregators and Imputers","text":"Let us create Date, Value input with some missing values and apply TSML functions to normalize/clean the data:","category":"page"},{"location":"tutorial/aggregators.html#","page":"Aggregators and Imputers","title":"Aggregators and Imputers","text":"using Random, Dates, DataFrames\nfunction generateDataWithMissing()\n   Random.seed!(123)\n   gdate = DateTime(2014,1,1):Dates.Minute(15):DateTime(2016,1,1)\n   gval = Array{Union{Missing,Float64}}(rand(length(gdate)))\n   gmissing = 50000\n   gndxmissing = Random.shuffle(1:length(gdate))[1:gmissing]\n   df = DataFrame(Date=gdate,Value=gval)\n   df[:Value][gndxmissing] .= missing\n   return df\nend","category":"page"},{"location":"tutorial/aggregators.html#","page":"Aggregators and Imputers","title":"Aggregators and Imputers","text":"Let's output the first 20 rows:","category":"page"},{"location":"tutorial/aggregators.html#","page":"Aggregators and Imputers","title":"Aggregators and Imputers","text":"X = generateDataWithMissing()\nfirst(X,20)","category":"page"},{"location":"tutorial/aggregators.html#DateValgator-1","page":"Aggregators and Imputers","title":"DateValgator","text":"","category":"section"},{"location":"tutorial/aggregators.html#","page":"Aggregators and Imputers","title":"Aggregators and Imputers","text":"You'll notice several blocks of missing with reading frequency every 15 minutes.  Let's aggregate our dataset by taking the hourly median using the DateValgator transformer.","category":"page"},{"location":"tutorial/aggregators.html#","page":"Aggregators and Imputers","title":"Aggregators and Imputers","text":"using TSML\nusing TSML.TSMLTypes\nusing TSML.Utils\nusing TSML.TSMLTransformers\nusing TSML: DateValgator\n\ndtvlgator = DateValgator(Dict(:dateinterval=>Dates.Hour(1)))\nfit!(dtvlgator,X)\nresults = transform!(dtvlgator,X)\nfirst(results,20)","category":"page"},{"location":"tutorial/aggregators.html#","page":"Aggregators and Imputers","title":"Aggregators and Imputers","text":"Missing values are now reduced because of the aggregation applied using DateValgator transformer. TSML transformers support the two main functions: fit! and transform!. DateValgator fit! performs initial setups of necessary parameters and validation of arguments while its transform! contains the algorithm for aggregation.","category":"page"},{"location":"tutorial/aggregators.html#DateValNNer-1","page":"Aggregators and Imputers","title":"DateValNNer","text":"","category":"section"},{"location":"tutorial/aggregators.html#","page":"Aggregators and Imputers","title":"Aggregators and Imputers","text":"Let's perform further processing to replace the remaining missing values with their nearest neighbors.  We will use DateValNNer which is a TSML transformer to process the output of DateValgator. DateValNNer can also process non-aggregated data by first running similar workflow of DateValgator before performing its imputation routine.","category":"page"},{"location":"tutorial/aggregators.html#","page":"Aggregators and Imputers","title":"Aggregators and Imputers","text":"using TSML: DateValNNer\n\ndatevalnner = DateValNNer(Dict(:dateinterval=>Dates.Hour(1)))\nfit!(datevalnner, X)\nresults = transform!(datevalnner,X)\nfirst(results,20)","category":"page"},{"location":"tutorial/aggregators.html#","page":"Aggregators and Imputers","title":"Aggregators and Imputers","text":"After running the DateValNNer, it's guaranteed that there will be no more missing data. ","category":"page"},{"location":"tutorial/aggregators.html#DateValizer-1","page":"Aggregators and Imputers","title":"DateValizer","text":"","category":"section"},{"location":"tutorial/aggregators.html#","page":"Aggregators and Imputers","title":"Aggregators and Imputers","text":"One more imputer to replace missing data is DateValizer. It computes the hourly median over 24 hours and use the hour => median mapping  to replace missing data with the hour as the key. Below is a sample workflow to replace missing data in X with the hourly medians.","category":"page"},{"location":"tutorial/aggregators.html#","page":"Aggregators and Imputers","title":"Aggregators and Imputers","text":"using TSML: DateValizer\n\ndatevalizer = DateValizer(Dict(:dateinterval=>Dates.Hour(1)))\nfit!(datevalizer, X)\nresults = transform!(datevalizer,X)\nfirst(results,20)","category":"page"},{"location":"tutorial/pipeline.html#","page":"Pipeline","title":"Pipeline","text":"Author = \"Paulito P. Palmes\"","category":"page"},{"location":"tutorial/pipeline.html#Pipeline-1","page":"Pipeline","title":"Pipeline","text":"","category":"section"},{"location":"tutorial/pipeline.html#","page":"Pipeline","title":"Pipeline","text":"Instead of calling fit! and transform! to process time-series data, we can use the Pipeline transformer which does this automatically by iterating the transformers passed throught its argument and calling fit! and transform repeatedly for each transformer.","category":"page"},{"location":"tutorial/pipeline.html#","page":"Pipeline","title":"Pipeline","text":"Let's have a function to generate dataframe with missing data.","category":"page"},{"location":"tutorial/pipeline.html#","page":"Pipeline","title":"Pipeline","text":"using Random, Dates, DataFrames\nfunction generateDataWithMissing()\n   Random.seed!(123)\n   gdate = DateTime(2014,1,1):Dates.Minute(15):DateTime(2016,1,1)\n   gval = Array{Union{Missing,Float64}}(rand(length(gdate)))\n   gmissing = 50000\n   gndxmissing = Random.shuffle(1:length(gdate))[1:gmissing]\n   df = DataFrame(Date=gdate,Value=gval)\n   df[:Value][gndxmissing] .= missing\n   return df\nend\n\nX = generateDataWithMissing()\nfirst(X,20)","category":"page"},{"location":"tutorial/pipeline.html#Workflow-of-Pipeline-1","page":"Pipeline","title":"Workflow of Pipeline","text":"","category":"section"},{"location":"tutorial/pipeline.html#","page":"Pipeline","title":"Pipeline","text":"Let's use the pipeline transformer to aggregate and impute:","category":"page"},{"location":"tutorial/pipeline.html#","page":"Pipeline","title":"Pipeline","text":"using Dates\nusing TSML\nusing TSML.TSMLTypes\nusing TSML.TSMLTransformers\nusing TSML: Pipeline\nusing TSML: DateValgator\nusing TSML: DateValNNer\n\ndtvalgator = DateValgator(Dict(:dateinterval => Dates.Hour(1)))\ndtvalnner = DateValNNer(Dict(:dateinterval => Dates.Hour(1)))\n\nmypipeline = Pipeline(\n  Dict( :transformers => [\n            dtvalgator,\n            dtvalnner\n         ]\n  )\n)\n\nfit!(mypipeline,X)\nresults = transform!(mypipeline,X)\nfirst(results,10)","category":"page"},{"location":"tutorial/pipeline.html#","page":"Pipeline","title":"Pipeline","text":"Using the Pipeline transformer, it becomes straightforward to process the time-series data. It also becomes trivial to extend TSML functionality by adding more transformers and making sure each support the fit! and transform! interfaces. Any new transformer can then be easily added to the Pipeline workflow  without invasively changing existing codes.","category":"page"},{"location":"tutorial/pipeline.html#Extending-TSML-1","page":"Pipeline","title":"Extending TSML","text":"","category":"section"},{"location":"tutorial/pipeline.html#","page":"Pipeline","title":"Pipeline","text":"To illustrate how simple it is to add a new transformer, below illustrates  extending TSML to support CSV reading which will then be added in the pipeline:","category":"page"},{"location":"tutorial/pipeline.html#","page":"Pipeline","title":"Pipeline","text":"using TSML.TSMLTypes\nimport TSML.TSMLTypes.fit!\nimport TSML.TSMLTypes.transform!\n\nusing CSV\n\nmutable struct CSVReader <: Transformer\n    model\n    args\n    function CSVReader(args=Dict())\n        default_args = Dict(\n            :filename => \"\",\n            :dateformat => \"\"\n        )\n        new(nothing,mergedict(default_args,args))\n    end\nend\n\nfunction fit!(csvrdr::CSVReader,x::T=[],y::Vector=[]) where {T<:Union{DataFrame,Vector,Matrix}}\n    fname = csvrdr.args[:filename]\n    fmt = csvrdr.args[:dateformat]\n    (fname != \"\" && fmt != \"\") || error(\"missing filename or date format\")\n    model = csvrdr.args\nend\n\nfunction transform!(csvrdr::CSVReader,x::T=[]) where {T<:Union{DataFrame,Vector,Matrix}}\n    fname = csvrdr.args[:filename]\n    fmt = csvrdr.args[:dateformat]\n    df = CSV.read(fname)\n    ncol(df) == 2 || error(\"dataframe should have only two columns: Date,Value\")\n    rename!(df,names(df)[1]=>:Date,names(df)[2]=>:Value)\n    df[:Date] = DateTime.(df[:Date],fmt)\n    df\nend","category":"page"},{"location":"tutorial/pipeline.html#","page":"Pipeline","title":"Pipeline","text":"Instead of passing input X, we will add an instance of the  CSVReader at the start of the array of transformers in the pipeline  to read the data and pass its output to the other transformers for processing.","category":"page"},{"location":"tutorial/pipeline.html#","page":"Pipeline","title":"Pipeline","text":"fname = joinpath(dirname(pathof(TSML)),\"../data/testdata.csv\")\ncsvreader = CSVReader(Dict(:filename=>fname,:dateformat=>\"d/m/y H:M\"))\nfit!(csvreader)\ncsvdata = transform!(csvreader)\nfirst(csvdata,10)","category":"page"},{"location":"tutorial/pipeline.html#","page":"Pipeline","title":"Pipeline","text":"Let us now include the newly created CSVReader in the pipeline to read the csv data and process it by aggregation and imputation.","category":"page"},{"location":"tutorial/pipeline.html#","page":"Pipeline","title":"Pipeline","text":"mypipeline = Pipeline(\n  Dict( :transformers => [\n            csvreader,\n            dtvalgator,\n            dtvalnner\n         ]\n  )\n)\n\nfit!(mypipeline)\nresults = transform!(mypipeline)\nfirst(results,10)","category":"page"},{"location":"tutorial/pipeline.html#","page":"Pipeline","title":"Pipeline","text":"Notice that there is no more the need to pass X in the arguments of fit! and transform because the data is now transmitted by the CSVReader instance to the other transformers in the pipeline.","category":"page"},{"location":"tutorial/statistics.html#","page":"Statistical Metrics","title":"Statistical Metrics","text":"Author = \"Paulito P. Palmes\"","category":"page"},{"location":"tutorial/statistics.html#Statistical-Metrics-1","page":"Statistical Metrics","title":"Statistical Metrics","text":"","category":"section"},{"location":"tutorial/statistics.html#","page":"Statistical Metrics","title":"Statistical Metrics","text":"Let us again start generating an artificial data with missing values which we  will use in our demo tutorial.","category":"page"},{"location":"tutorial/statistics.html#","page":"Statistical Metrics","title":"Statistical Metrics","text":"using Random, Dates, DataFrames\nfunction generateDataWithMissing()\n   Random.seed!(123)\n   gdate = DateTime(2014,1,1):Dates.Minute(15):DateTime(2016,1,1)\n   gval = Array{Union{Missing,Float64}}(rand(length(gdate)))\n   gmissing = 50000\n   gndxmissing = Random.shuffle(1:length(gdate))[1:gmissing]\n   df = DataFrame(Date=gdate,Value=gval)\n   df[:Value][gndxmissing] .= missing\n   return df\nend\n\nX = generateDataWithMissing()\nfirst(X,20)","category":"page"},{"location":"tutorial/statistics.html#Statifier-1","page":"Statistical Metrics","title":"Statifier","text":"","category":"section"},{"location":"tutorial/statistics.html#","page":"Statistical Metrics","title":"Statistical Metrics","text":"TSML includes Statifier transformer that computes scalar statistics to characterize the time-series data. By default, it also computes statistics of  missing blocks of data. To disable this feature, one can pass  :processmissing => false to the argument during its instance creation. Below illustrates this workflow.","category":"page"},{"location":"tutorial/statistics.html#","page":"Statistical Metrics","title":"Statistical Metrics","text":"using Dates\nusing TSML\nusing TSML.TSMLTypes\nusing TSML.TSMLTransformers\nusing TSML: Pipeline\nusing TSML: DateValgator\nusing TSML: DateValNNer\nusing TSML: Statifier\n\ndtvalgator = DateValgator(Dict(:dateinterval => Dates.Hour(1)))\ndtvalnner = DateValNNer(Dict(:dateinterval => Dates.Hour(1)))\ndtvalizer = DateValizer(Dict(:dateinterval => Dates.Hour(1)))\nstfier = Statifier()\n\nmypipeline = Pipeline(\n  Dict( :transformers => [\n            dtvalgator,\n            stfier\n         ]\n  )\n)\n\nfit!(mypipeline,X)\nresults = transform!(mypipeline,X)","category":"page"},{"location":"tutorial/statistics.html#","page":"Statistical Metrics","title":"Statistical Metrics","text":"If you are not intested with the statistics of the missing blocks, you can indicate :processmissing => false in the instance argument.","category":"page"},{"location":"tutorial/statistics.html#","page":"Statistical Metrics","title":"Statistical Metrics","text":"stfier = Statifier(Dict(:processmissing=>false))\nmypipeline = Pipeline(\n  Dict( :transformers => [\n            dtvalgator,\n            stfier\n         ]\n  )\n)\nfit!(mypipeline,X)\nresults = transform!(mypipeline,X)","category":"page"},{"location":"tutorial/statistics.html#","page":"Statistical Metrics","title":"Statistical Metrics","text":"Let us check the statistics after the imputation. We expect that if the imputation is successful, the stats for missing blocks will all be NaN because stats of empty set is an NaN.","category":"page"},{"location":"tutorial/statistics.html#","page":"Statistical Metrics","title":"Statistical Metrics","text":"stfier = Statifier(Dict(:processmissing=>true))\nmypipeline = Pipeline(\n  Dict( :transformers => [\n            dtvalgator,\n            dtvalnner,\n            stfier\n         ]\n  )\n)\nfit!(mypipeline,X)\nresults = transform!(mypipeline,X)","category":"page"},{"location":"tutorial/statistics.html#","page":"Statistical Metrics","title":"Statistical Metrics","text":"As we expected, the imputation is successful and there are no more missing values in the processed time-series dataset.","category":"page"},{"location":"tutorial/statistics.html#","page":"Statistical Metrics","title":"Statistical Metrics","text":"Let's try with the other imputation using DateValizer and validate that there are no more missing values based on the stats.","category":"page"},{"location":"tutorial/statistics.html#","page":"Statistical Metrics","title":"Statistical Metrics","text":"stfier = Statifier(Dict(:processmissing=>true))\nmypipeline = Pipeline(\n  Dict( :transformers => [\n            dtvalgator,\n            dtvalizer,\n            stfier\n         ]\n  )\n)\nfit!(mypipeline,X)\nresults = transform!(mypipeline,X)","category":"page"},{"location":"tutorial/statistics.html#","page":"Statistical Metrics","title":"Statistical Metrics","text":"Indeed, the imputation is a success.","category":"page"},{"location":"tutorial/tsdetectors.html#","page":"TS Data Discovery","title":"TS Data Discovery","text":"Author = \"Paulito P. Palmes\"","category":"page"},{"location":"tutorial/tsdetectors.html#TS-Data-Discovery-1","page":"TS Data Discovery","title":"TS Data Discovery","text":"","category":"section"},{"location":"man/dateproc.html#","page":"Date Processing","title":"Date Processing","text":"Author = \"Paulito P. Palmes\"","category":"page"},{"location":"man/dateproc.html#Preprocessing-1","page":"Date Processing","title":"Preprocessing","text":"","category":"section"},{"location":"man/valueproc.html#","page":"Value Processing","title":"Value Processing","text":"Author = \"Paulito P. Palmes\"","category":"page"},{"location":"man/valueproc.html#Value-Preprocessing-1","page":"Value Processing","title":"Value Preprocessing","text":"","category":"section"},{"location":"man/aggregation.html#","page":"Aggregation","title":"Aggregation","text":"Author = \"Paulito P. Palmes\"","category":"page"},{"location":"man/aggregation.html#Aggregation-1","page":"Aggregation","title":"Aggregation","text":"","category":"section"},{"location":"man/imputation.html#","page":"Imputation","title":"Imputation","text":"Author = \"Paulito P. Palmes\"","category":"page"},{"location":"man/imputation.html#Imputation-1","page":"Imputation","title":"Imputation","text":"","category":"section"},{"location":"man/monotonic.html#","page":"Monotonic Detection","title":"Monotonic Detection","text":"Author = \"Paulito P. Palmes\"","category":"page"},{"location":"man/monotonic.html#Monotonic-Detection-1","page":"Monotonic Detection","title":"Monotonic Detection","text":"","category":"section"},{"location":"man/tsclassification.html#","page":"TS Classification","title":"TS Classification","text":"Author = \"Paulito P. Palmes\"","category":"page"},{"location":"man/tsclassification.html#TS-Classification-1","page":"TS Classification","title":"TS Classification","text":"","category":"section"},{"location":"man/cli.html#","page":"CLI Wrappers","title":"CLI Wrappers","text":"Author = \"Paulito P. Palmes\"","category":"page"},{"location":"man/cli.html#CLI-Wrappers-1","page":"CLI Wrappers","title":"CLI Wrappers","text":"","category":"section"},{"location":"lib/decisiontree.html#","page":"Decision Tree","title":"Decision Tree","text":"Author = \"Paulito Palmes\"","category":"page"},{"location":"lib/decisiontree.html#lib_decisiontree-1","page":"Decision Tree","title":"DecisionTreeLearners","text":"","category":"section"},{"location":"lib/decisiontree.html#","page":"Decision Tree","title":"Decision Tree","text":"Creates an API wrapper for DecisionTrees for pipeline workflow.","category":"page"},{"location":"lib/decisiontree.html#","page":"Decision Tree","title":"Decision Tree","text":"Modules = [DecisionTreeLearners]","category":"page"},{"location":"lib/decisiontree.html#","page":"Decision Tree","title":"Decision Tree","text":"Modules = [DecisionTreeLearners]","category":"page"}]
}
