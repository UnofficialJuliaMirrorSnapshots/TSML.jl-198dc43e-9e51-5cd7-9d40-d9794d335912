{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load TSML filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using TSML\n",
    "using TSML.Utils\n",
    "using TSML.TSMLTypes\n",
    "\n",
    "using TSML: CSVDateValReader, CSVDateValWriter, Statifier\n",
    "using TSML: Monotonicer, Outliernicer, Plotter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create artificial data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using Dates\n",
    "using Random\n",
    "\n",
    "ENV[\"COLUMNS\"]=1000 # for dataframe column size\n",
    "\n",
    "function generateXY()\n",
    "    Random.seed!(123)\n",
    "    gdate = DateTime(2014,1,1):Dates.Minute(15):DateTime(2014,1,5)\n",
    "    gval = Array{Union{Missing,Float64}}(rand(length(gdate)))\n",
    "    gmissing = floor(0.30*length(gdate)) |> Integer\n",
    "    gndxmissing = Random.shuffle(1:length(gdate))[1:gmissing]\n",
    "    X = DataFrame(Date=gdate,Value=gval)\n",
    "    X.Value[gndxmissing] .= missing\n",
    "    Y = rand(length(gdate))\n",
    "    (X,Y)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate artificial data with missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df,outY)=generateXY()\n",
    "first(df,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Pipeline and Plotter to plot artificial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltr=Plotter(Dict(:interactive => false))\n",
    "\n",
    "mypipeline = Pipeline(Dict(\n",
    "  :transformers => [pltr]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(mypipeline, df)\n",
    "transform!(mypipeline, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get statistics including blocks of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statfier = Statifier(Dict(:processmissing=>true))\n",
    "\n",
    "mypipeline = Pipeline(Dict(\n",
    "  :transformers => [statfier]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(mypipeline, df)\n",
    "res = transform!(mypipeline, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Pipeline: aggregate, impute, and plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valgator = DateValgator(Dict(:dateinterval=>Dates.Hour(1)))\n",
    "valnner = DateValNNer(Dict(:dateinterval=>Dates.Hour(1)))\n",
    "\n",
    "mypipeline = Pipeline(Dict(\n",
    "  :transformers => [valgator,pltr]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(mypipeline, df)\n",
    "transform!(mypipeline, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = joinpath(dirname(pathof(TSML)),\"../data/testdata.csv\")\n",
    "csvreader = CSVDateValReader(Dict(:filename=>fname,:dateformat=>\"dd/mm/yyyy HH:MM\"))\n",
    "\n",
    "outputname = joinpath(dirname(pathof(TSML)),\"/tmp/testdata_output.csv\")\n",
    "csvwriter = CSVDateValWriter(Dict(:filename=>outputname))\n",
    "\n",
    "valgator = DateValgator(Dict(:dateinterval=>Dates.Hour(1)))\n",
    "valnner = DateValNNer(Dict(:dateinterval=>Dates.Hour(1)))\n",
    "stfier = Statifier(Dict(:processmissing=>true))\n",
    "outliernicer = Outliernicer(Dict(:dateinterval=>Dates.Hour(1)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot real data with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpipeline1 = Pipeline(Dict(\n",
    "  :transformers => [csvreader,valgator,pltr]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(mpipeline1)\n",
    "transform!(mpipeline1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get statistics including blocks of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpipeline1 = Pipeline(Dict(\n",
    "  :transformers => [csvreader,valgator,stfier]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(mpipeline1)\n",
    "respipe1 = transform!(mpipeline1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try imputing and get statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpipeline2 = Pipeline(Dict(\n",
    "  :transformers => [csvreader,valgator,valnner,stfier]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(mpipeline2)\n",
    "respipe2 = transform!(mpipeline2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot imputted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpipeline2 = Pipeline(Dict(\n",
    "  :transformers => [csvreader,valgator,valnner,pltr]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(mpipeline2)\n",
    "transform!(mpipeline2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monotonicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularfile = joinpath(dirname(pathof(TSML)),\"../data/typedetection/regular.csv\")\n",
    "monofile = joinpath(dirname(pathof(TSML)),\"../data/typedetection/monotonic.csv\")\n",
    "dailymonofile = joinpath(dirname(pathof(TSML)),\"../data/typedetection/dailymonotonic.csv\")\n",
    "\n",
    "regularfilecsv = CSVDateValReader(Dict(:filename=>regularfile,:dateformat=>\"dd/mm/yyyy HH:MM\"))\n",
    "monofilecsv = CSVDateValReader(Dict(:filename=>monofile,:dateformat=>\"dd/mm/yyyy HH:MM\"))\n",
    "dailymonofilecsv = CSVDateValReader(Dict(:filename=>dailymonofile,:dateformat=>\"dd/mm/yyyy HH:MM\"))\n",
    "\n",
    "valgator = DateValgator(Dict(:dateinterval=>Dates.Hour(1)))\n",
    "valnner = DateValNNer(Dict(:dateinterval=>Dates.Hour(1)))\n",
    "stfier = Statifier(Dict(:processmissing=>true))\n",
    "mono = Monotonicer(Dict())\n",
    "stfier = Statifier(Dict(:processmissing=>true))\n",
    "outliernicer = Outliernicer(Dict(:dateinterval=>Dates.Hour(1)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of monotonic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monopipeline = Pipeline(Dict(\n",
    "  :transformers => [monofilecsv,valgator,valnner,pltr]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(monopipeline)\n",
    "transform!(monopipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot after normalization of monotonic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monopipeline = Pipeline(Dict(\n",
    "  :transformers => [monofilecsv,valgator,valnner,mono,pltr]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(monopipeline)\n",
    "transform!(monopipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot with Monotonicer and Outliernicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monopipeline = Pipeline(Dict(\n",
    "  :transformers => [monofilecsv,valgator,valnner,mono,outliernicer,pltr]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(monopipeline)\n",
    "transform!(monopipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of daily monotonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailymonopipeline = Pipeline(Dict(\n",
    "  :transformers => [dailymonofilecsv,valgator,valnner,pltr]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(dailymonopipeline)\n",
    "transform!(dailymonopipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of daily monotonic data with Monotonicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailymonopipeline = Pipeline(Dict(\n",
    "  :transformers => [dailymonofilecsv,valgator,valnner,mono,pltr]\n",
    " )\n",
    ")\n",
    "fit!(dailymonopipeline)\n",
    "transform!(dailymonopipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of daily monotonic with Monotonicer and Outliernicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailymonopipeline = Pipeline(Dict(\n",
    "  :transformers => [dailymonofilecsv,valgator,valnner,mono,outliernicer,pltr]\n",
    " )\n",
    ")\n",
    "fit!(dailymonopipeline)\n",
    "transform!(dailymonopipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot regular TS after monotonic normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regpipeline = Pipeline(Dict(\n",
    "  :transformers => [regularfilecsv,valgator,valnner,mono,pltr]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(regpipeline)\n",
    "transform!(regpipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of regular TS with outlier normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regpipeline = Pipeline(Dict(\n",
    "  :transformers => [regularfilecsv,valgator,valnner,mono,outliernicer,pltr]\n",
    " )\n",
    ")\n",
    "fit!(regpipeline)\n",
    "transform!(regpipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TS Discovery by automatic data type classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using TSML: TSClassifier\n",
    "Random.seed!(12)\n",
    "\n",
    "trdirname = joinpath(dirname(pathof(TSML)),\"../data/realdatatsclassification/training\")\n",
    "tstdirname = joinpath(dirname(pathof(TSML)),\"../data/realdatatsclassification/testing\")\n",
    "modeldirname = joinpath(dirname(pathof(TSML)),\"../data/realdatatsclassification/model\")\n",
    "\n",
    "tscl = TSClassifier(Dict(:trdirectory=>trdirname,\n",
    "           :tstdirectory=>tstdirname,\n",
    "           :modeldirectory=>modeldirname,\n",
    "           :feature_range => 6:20,\n",
    "           :num_trees=>10)\n",
    ")\n",
    "\n",
    "fit!(tscl)\n",
    "dfresults = transform!(tscl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apredict = dfresults[:predtype]\n",
    "fnames = dfresults[:fname]\n",
    "myregex = r\"(?<dtype>[A-Z _ - a-z]+)(?<number>\\d*).(?<ext>\\w+)\"\n",
    "mtypes=map(fnames) do fname\n",
    "  mymatch=match(myregex,fname)\n",
    "  mymatch[:dtype]\n",
    "end\n",
    "\n",
    "sum(mtypes .== apredict)/length(mtypes) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.2",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
