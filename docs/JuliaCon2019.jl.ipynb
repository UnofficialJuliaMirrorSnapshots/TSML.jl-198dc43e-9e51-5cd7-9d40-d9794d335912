{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TSML (Time Series Machine Learning)\n",
    "- **Speaker:  Paulito Palmes**\n",
    "- **IBM Dublin Research Lab**\n",
    "- July 23, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Motivations\n",
    "- innovations in industry sectors brought automations \n",
    "- automations require installation of sensor networks \n",
    "- main challenges:\n",
    "  - collect large volume of data, detect anomalies, monitor status\n",
    "  - discover patterns to reduce downtimes and manufacturing errors\n",
    "  - reduce energy usage\n",
    "  - predict faults/failures\n",
    "  - effective maintenance schedules\n",
    "\n",
    "_TSML leverages AI and ML libraries from ScikitLearn, Caret, and Julia as building blocks for processing huge amount of industrial time series data._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Typical TSML Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## First, let's create an artificial data with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using Dates\n",
    "using Random\n",
    "ENV[\"COLUMNS\"]=1000 # for dataframe column size\n",
    "\n",
    "function generateXY()\n",
    "    Random.seed!(123)\n",
    "    gdate = DateTime(2014,1,1):Dates.Minute(15):DateTime(2014,1,5)\n",
    "    gval = Array{Union{Missing,Float64}}(rand(length(gdate)))\n",
    "    gmissing = floor(0.30*length(gdate)) |> Integer\n",
    "    gndxmissing = Random.shuffle(1:length(gdate))[1:gmissing]\n",
    "    X = DataFrame(Date=gdate,Value=gval)\n",
    "    X.Value[gndxmissing] .= missing\n",
    "    Y = rand(length(gdate))\n",
    "    (X,Y)\n",
    "end;\n",
    "(df,outY)=generateXY(); first(df,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's load the TSML modules and filters to process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "using TSML\n",
    "using TSML.Utils\n",
    "using TSML.TSMLTypes\n",
    "using TSML: CSVDateValReader, CSVDateValWriter, Statifier\n",
    "using TSML: Monotonicer, Outliernicer, Plotter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's use Pipeline with Plotter filter to plot artificial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pltr=Plotter(Dict(:interactive => true))\n",
    "\n",
    "mypipeline = Pipeline(Dict(\n",
    "  :transformers => [pltr]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(mypipeline, df)\n",
    "transform!(mypipeline, df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's get the statistics/data quality including blocks of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "statfier = Statifier(Dict(:processmissing=>true))\n",
    "\n",
    "mypipeline = Pipeline(Dict(\n",
    "  :transformers => [statfier]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(mypipeline, df)\n",
    "res = transform!(mypipeline, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's extend the Pipeline workflow with aggregate, impute, and plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "valgator = DateValgator(Dict(:dateinterval=>Dates.Hour(1)))\n",
    "\n",
    "mypipeline = Pipeline(Dict(\n",
    "  :transformers => [valgator,pltr]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(mypipeline, df)\n",
    "transform!(mypipeline, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's now try real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fname = joinpath(dirname(pathof(TSML)),\"../data/testdata.csv\")\n",
    "csvreader = CSVDateValReader(Dict(:filename=>fname,:dateformat=>\"dd/mm/yyyy HH:MM\"))\n",
    "\n",
    "outputname = joinpath(dirname(pathof(TSML)),\"/tmp/testdata_output.csv\")\n",
    "csvwriter = CSVDateValWriter(Dict(:filename=>outputname))\n",
    "\n",
    "valgator = DateValgator(Dict(:dateinterval=>Dates.Hour(1)))\n",
    "valputer = DateValNNer(Dict(:dateinterval=>Dates.Hour(1)))\n",
    "stfier = Statifier(Dict(:processmissing=>true))\n",
    "outliernicer = Outliernicer(Dict(:dateinterval=>Dates.Hour(1)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's plot the real data and check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mpipeline1 = Pipeline(Dict(\n",
    "  :transformers => [csvreader,valgator,pltr]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(mpipeline1)\n",
    "transform!(mpipeline1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's get the statistics to assess data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mpipeline1 = Pipeline(Dict(\n",
    "  :transformers => [csvreader,valgator,stfier]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(mpipeline1)\n",
    "respipe1 = transform!(mpipeline1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's try imputing and verify the statistical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mpipeline2 = Pipeline(Dict(\n",
    "  :transformers => [csvreader,valgator,valputer,statfier]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(mpipeline2)\n",
    "respipe2 = transform!(mpipeline2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's visualize the imputted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mpipeline2 = Pipeline(Dict(\n",
    "  :transformers => [csvreader,valgator,valputer,pltr]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(mpipeline2)\n",
    "transform!(mpipeline2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's have examples of Monotonic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "regularfile = joinpath(dirname(pathof(TSML)),\"../data/typedetection/regular.csv\")\n",
    "monofile = joinpath(dirname(pathof(TSML)),\"../data/typedetection/monotonic.csv\")\n",
    "dailymonofile = joinpath(dirname(pathof(TSML)),\"../data/typedetection/dailymonotonic.csv\")\n",
    "\n",
    "regularfilecsv = CSVDateValReader(Dict(:filename=>regularfile,:dateformat=>\"dd/mm/yyyy HH:MM\"))\n",
    "monofilecsv = CSVDateValReader(Dict(:filename=>monofile,:dateformat=>\"dd/mm/yyyy HH:MM\"))\n",
    "dailymonofilecsv = CSVDateValReader(Dict(:filename=>dailymonofile,:dateformat=>\"dd/mm/yyyy HH:MM\"))\n",
    "\n",
    "valgator = DateValgator(Dict(:dateinterval=>Dates.Hour(1)))\n",
    "valputer = DateValNNer(Dict(:dateinterval=>Dates.Hour(1)))\n",
    "stfier = Statifier(Dict(:processmissing=>true))\n",
    "mononicer = Monotonicer(Dict())\n",
    "stfier = Statifier(Dict(:processmissing=>true))\n",
    "outliernicer = Outliernicer(Dict(:dateinterval=>Dates.Hour(1)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's plot an example of monotonic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "monopipeline = Pipeline(Dict(\n",
    "  :transformers => [monofilecsv,valgator,valputer,pltr]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(monopipeline)\n",
    "transform!(monopipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's plot after normalizing the monotonic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "monopipeline = Pipeline(Dict(\n",
    "  :transformers => [monofilecsv,valgator,valputer,mononicer, pltr]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(monopipeline)\n",
    "transform!(monopipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's remove outliers and plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "monopipeline = Pipeline(Dict(\n",
    "  :transformers => [monofilecsv,valgator,valputer,mononicer,outliernicer,pltr]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(monopipeline)\n",
    "transform!(monopipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's plot and example of a daily monotonic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dailymonopipeline = Pipeline(Dict(\n",
    "  :transformers => [dailymonofilecsv,valgator,valputer,pltr]\n",
    " )\n",
    ")\n",
    "\n",
    "fit!(dailymonopipeline)\n",
    "transform!(dailymonopipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's normalize and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dailymonopipeline = Pipeline(Dict(\n",
    "  :transformers => [dailymonofilecsv,valgator,valputer,mononicer,pltr]\n",
    " )\n",
    ")\n",
    "fit!(dailymonopipeline)\n",
    "transform!(dailymonopipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's add the Outliernicer filter and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dailymonopipeline = Pipeline(Dict(\n",
    "  :transformers => [dailymonofilecsv,valgator,valputer,mononicer,outliernicer,pltr]\n",
    " )\n",
    ")\n",
    "fit!(dailymonopipeline)\n",
    "transform!(dailymonopipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's use what we have learned so far to perform automatic data type classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "using TSML: TSClassifier\n",
    "Random.seed!(12)\n",
    "\n",
    "trdirname = joinpath(dirname(pathof(TSML)),\"../data/realdatatsclassification/training\")\n",
    "tstdirname = joinpath(dirname(pathof(TSML)),\"../data/realdatatsclassification/testing\")\n",
    "modeldirname = joinpath(dirname(pathof(TSML)),\"../data/realdatatsclassification/model\")\n",
    "\n",
    "tscl = TSClassifier(Dict(:trdirectory=>trdirname,\n",
    "           :tstdirectory=>tstdirname,\n",
    "           :modeldirectory=>modeldirname,\n",
    "           :feature_range => 6:20,\n",
    "           :num_trees=>50)\n",
    ")\n",
    "\n",
    "fit!(tscl)\n",
    "dfresults = transform!(tscl);\n",
    "apredict = dfresults.predtype\n",
    "fnames = dfresults.fname\n",
    "myregex = r\"(?<dtype>[A-Z _ - a-z]+)(?<number>\\d*).(?<ext>\\w+)\"\n",
    "mtypes=map(fnames) do fname\n",
    "  mymatch=match(myregex,fname)\n",
    "  mymatch[:dtype]\n",
    "end\n",
    "\n",
    "sum(mtypes .== apredict)/length(mtypes) * 100 |> x-> round(x,digits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TSML features\n",
    "- TS data type clustering/classification for automatic data discovery\n",
    "- TS aggregation based on date/time interval\n",
    "- TS imputation based on symmetric Nearest Neighbors\n",
    "- TS statistical metrics for data quality assessment\n",
    "- TS ML wrapper with more than 100+ libraries from caret, scikitlearn, and julia\n",
    "- TS date/value matrix conversion of 1-D TS using sliding windows for ML input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## More TSML features\n",
    "- Common API wrappers for ML libs from JuliaML, PyCall, and RCall\n",
    "- Pipeline API allows high-level description of the processing workflow\n",
    "- Specific cleaning/normalization workflow based on data type\n",
    "- Automatic selection of optimised ML model\n",
    "- Automatic segmentation of time-series data into matrix form for ML training and prediction\n",
    "- Easily extensible architecture by using just two main interfaces: fit and transform\n",
    "- Meta-ensembles for robust prediction\n",
    "- Support for distributed computation, for scalability, and speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "1ac647ed4c2c4f25b04d24b457237df1",
   "lastKernelId": "1092be05-a956-4969-8b42-0265c3f2410c"
  },
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.2",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
